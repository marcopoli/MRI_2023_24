{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ExbNueiSrQvr"
      },
      "source": [
        "## Text classification using Neural Networks, Gensim and Spacy\n",
        "\n",
        "The goal of this notebook is to learn to use Neural Networks for text classification.\n",
        "\n",
        "In this notebook, we will:\n",
        "- Train a shallow model with learning embeddings\n",
        "- Download pre-trained embeddings from FastTextAi\n",
        "- Use these pre-trained embeddings\n",
        "\n",
        "However keep in mind:\n",
        "- Deep Learning can be better on text classification that simpler ML techniques, but only on very large datasets and well designed/tuned models.\n",
        "- We won't be using the most efficient (in terms of computing) techniques, as Keras is good for prototyping but rather inefficient for training small embedding models on text.\n",
        "- The following projects can replicate similar word embedding models much more efficiently: [word2vec](https://github.com/dav/word2vec) and [gensim's word2vec](https://radimrehurek.com/gensim/models/word2vec.html)   (self-supervised learning only), [fastText](https://github.com/facebookresearch/fastText) (both supervised and self-supervised learning), [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki) (supervised learning).\n",
        "- Plain shallow sparse TF-IDF bigrams features without any embedding and Logistic Regression or Multinomial Naive Bayes is often competitive in small to medium datasets.\n",
        "\n",
        "\n",
        "### Sentipolc 2016\n",
        "\n",
        "It is the intention of the organizers to promote the construction of a shared dataset for both Sentipolc and the Named Entity rEcognition and Linking in Italian Tweets (NEEL-IT) Evalita 2016 task. Indeed, interest in entity-liking in Twitter is gaining increasing attention, as well as aspect-based sentiment analysis. In a world where e-commerce is part of our everyday life and social media platforms are regarded as new channels for marketing and for fostering trust of potential customers, such great interest in opinion mining from Twitter isn’t surprising. In this scenario, it is crucial to be able to mine opinions about specific aspects of objects and named entities. Therefore, we believe that besides the traditional task on message-level polarity classification, in the future editions of Evalita special focus should be given to entity-based sentiment analysis.\n",
        "The use of common data for the Sentipolc and NEEL-IT is a first step towards the long-term goal of enabling participants to develop end-to-end system from entity linking to entity-based sentiment analysis. http://www.di.unito.it/~tutreeb/sentipolc-evalita16/data.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.di.uniba.it/~swap/sentipolc/sentipolc16_train.csv\n",
        "!wget http://www.di.uniba.it/~swap/sentipolc/sentipolc16_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjB4ElyWu1WD",
        "outputId": "e857fcff-88cd-49ca-8201-bf5a16b95b30"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 09:15:19--  http://www.di.uniba.it/~swap/sentipolc/sentipolc16_train.csv\n",
            "Resolving www.di.uniba.it (www.di.uniba.it)... 193.204.187.10\n",
            "Connecting to www.di.uniba.it (www.di.uniba.it)|193.204.187.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1028257 (1004K) [text/plain]\n",
            "Saving to: ‘sentipolc16_train.csv.3’\n",
            "\n",
            "sentipolc16_train.c 100%[===================>]   1004K   888KB/s    in 1.1s    \n",
            "\n",
            "2023-12-11 09:15:22 (888 KB/s) - ‘sentipolc16_train.csv.3’ saved [1028257/1028257]\n",
            "\n",
            "--2023-12-11 09:15:22--  http://www.di.uniba.it/~swap/sentipolc/sentipolc16_test.csv\n",
            "Resolving www.di.uniba.it (www.di.uniba.it)... 193.204.187.10\n",
            "Connecting to www.di.uniba.it (www.di.uniba.it)|193.204.187.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 327873 (320K) [text/plain]\n",
            "Saving to: ‘sentipolc16_test.csv.3’\n",
            "\n",
            "sentipolc16_test.cs 100%[===================>] 320.19K   378KB/s    in 0.8s    \n",
            "\n",
            "2023-12-11 09:15:23 (378 KB/s) - ‘sentipolc16_test.csv.3’ saved [327873/327873]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uksPu2sRrQvt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train= pd.read_csv('sentipolc16_train.csv')\n",
        "test = pd.read_csv('sentipolc16_test.csv')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-51S4SXJbSgG",
        "outputId": "c4dd691c-55d8-4471-aa7b-5fb73fea38e8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               idtwitter  subj  opos  oneg  iro  lpos  lneg  top  \\\n",
              "0     122449983151669248     1     0     1    0     0     1    1   \n",
              "1     125485104863780865     1     0     1    0     0     1    1   \n",
              "2     125513454315507712     1     0     1    0     0     1    1   \n",
              "3     125524238290522113     1     0     1    0     0     1    1   \n",
              "4     125527933224886272     1     0     1    0     0     1    1   \n",
              "...                  ...   ...   ...   ...  ...   ...   ...  ...   \n",
              "7405  135136897000415233     1     1     0    1     1     1    1   \n",
              "7406  143471916534087680     1     1     0    1     1     0    1   \n",
              "7407  153955345411219456     1     0     1    1     1     0    1   \n",
              "7408  190835515552047104     1     1     0    1     1     1    0   \n",
              "7409  193068210763993088     1     1     0    1     1     1    1   \n",
              "\n",
              "                                                   text  \n",
              "0     Intanto la partita per Via Nazionale si compli...  \n",
              "1     False illusioni, sgradevoli realtà Mario Monti...  \n",
              "2     False illusioni, sgradevoli realtà #editoriale...  \n",
              "3     Mario Monti: Berlusconi risparmi all'Italia il...  \n",
              "4     Mario Monti: Berlusconi risparmi all'Italia il...  \n",
              "...                                                 ...  \n",
              "7405  che ci frega di mario monti, noi abbiamo mario...  \n",
              "7406  Strepitoso il titolo in prima di Libero sul go...  \n",
              "7407  @nataliacavalli Consolati, il governo #Monti h...  \n",
              "7408  @SheisCandida beh, beate loro! Io nn possiedo ...  \n",
              "7409  Caro #Renzi,se #Grillo spaccava i computer e o...  \n",
              "\n",
              "[7410 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c9ebc77-10c8-4ea1-86a6-09fc8659b552\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idtwitter</th>\n",
              "      <th>subj</th>\n",
              "      <th>opos</th>\n",
              "      <th>oneg</th>\n",
              "      <th>iro</th>\n",
              "      <th>lpos</th>\n",
              "      <th>lneg</th>\n",
              "      <th>top</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122449983151669248</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Intanto la partita per Via Nazionale si compli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125485104863780865</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False illusioni, sgradevoli realtà Mario Monti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125513454315507712</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False illusioni, sgradevoli realtà #editoriale...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>125524238290522113</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>125527933224886272</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7405</th>\n",
              "      <td>135136897000415233</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>che ci frega di mario monti, noi abbiamo mario...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7406</th>\n",
              "      <td>143471916534087680</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Strepitoso il titolo in prima di Libero sul go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7407</th>\n",
              "      <td>153955345411219456</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>@nataliacavalli Consolati, il governo #Monti h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7408</th>\n",
              "      <td>190835515552047104</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@SheisCandida beh, beate loro! Io nn possiedo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7409</th>\n",
              "      <td>193068210763993088</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Caro #Renzi,se #Grillo spaccava i computer e o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7410 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c9ebc77-10c8-4ea1-86a6-09fc8659b552')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c9ebc77-10c8-4ea1-86a6-09fc8659b552 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c9ebc77-10c8-4ea1-86a6-09fc8659b552');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41feb7d0-55a5-4b3a-9911-e8686ce0c106\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41feb7d0-55a5-4b3a-9911-e8686ce0c106')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41feb7d0-55a5-4b3a-9911-e8686ce0c106 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ukd0b5mrrQv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f7d3b1-79e8-4adb-d47e-550aa5c583e6"
      },
      "source": [
        "sample_idx = 1000\n",
        "print(train[\"text\"][sample_idx])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L'abuso della parola super per i ministri del governo #Monti è il segno di quanto in Italia si fosse(sia) persa la concezione del normale \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "J2qz0burrQv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ffb631-05a3-44a4-82a1-aaa6f87e9b5a"
      },
      "source": [
        "target_classes = train[\"opos\"]\n",
        "\n",
        "target_id = train[\"opos\"][sample_idx]\n",
        "print(\"Class of previous message:\", target_id)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class of previous message: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ZXRSh7XMrQwA"
      },
      "source": [
        "Here are all the possible classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4-ziROzGrQwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca6e6f0-47f9-4099-d56b-f7e1a1b1faf4"
      },
      "source": [
        "target_classes"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "7405    1\n",
              "7406    1\n",
              "7407    0\n",
              "7408    1\n",
              "7409    1\n",
              "Name: opos, Length: 7410, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FAsr1e6mrQwI"
      },
      "source": [
        "### Preprocessing text for the (supervised) CBOW model\n",
        "\n",
        "We will implement a simple classification model in Keras. Raw text requires (sometimes a lot of) preprocessing.\n",
        "\n",
        "The following cells uses Keras to preprocess text:\n",
        "- using a tokenizer. You may use different tokenizers (from scikit-learn, NLTK, custom Python function etc.). This converts the texts into sequences of indices representing the `20000` most frequent words\n",
        "- sequences have different lengths, so we pad them (add 0s at the end until the sequence is of length `1000`)\n",
        "- we convert the output classes as 1-hot encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "WO8Raa-CrQwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce84dc89-bfb5-4d01-dba2-e33025caf547"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "# get the raw text data\n",
        "texts_train = train[\"text\"]\n",
        "texts_test =test[\"text\"]\n",
        "\n",
        "# finally, vectorize the text samples into a 2D integer tensor\n",
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py:246: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21234 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "nuoLwWfsrQwP"
      },
      "source": [
        "Tokenized sequences are converted to list of token ids (with an integer code):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "scrolled": true,
        "id": "v14-T1htrQwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11090dc5-fdb0-4138-e8e1-e99a91d890d4"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[557,\n",
              " 11,\n",
              " 1081,\n",
              " 14,\n",
              " 47,\n",
              " 651,\n",
              " 22,\n",
              " 6520,\n",
              " 4070,\n",
              " 111,\n",
              " 10,\n",
              " 904,\n",
              " 34,\n",
              " 33,\n",
              " 15,\n",
              " 1,\n",
              " 7,\n",
              " 5,\n",
              " 6,\n",
              " 6521,\n",
              " 47,\n",
              " 977]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "he3oRoNLrQwX"
      },
      "source": [
        "The tokenizer object stores a mapping (vocabulary) from word strings to token ids that can be inverted to reconstruct the original message (without formatting):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "HWv9H-y3rQwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fb8d55-49ea-44b0-8c63-62d818533a27"
      },
      "source": [
        "type(tokenizer.word_index), len(tokenizer.word_index)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict, 21234)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7Whhbl7urQwd"
      },
      "source": [
        "index_to_word = dict((i, w) for w, i in tokenizer.word_index.items())"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "V9gVHtFLd9T9",
        "outputId": "52462bc7-2d43-41b1-dc88-1c26f4755f78"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Intanto la partita per Via Nazionale si complica. #Saccomanni dice che \"mica tutti sono Mario #Monti\" http://t.co/xPtNz4X7 via @linkiesta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "r3Y-rvEkrQwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5818aec5-fb57-42c9-a8bf-463d3af5edbe"
      },
      "source": [
        "\" \".join([index_to_word[i] for i in sequences[0]])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'intanto la partita per via nazionale si complica saccomanni dice che mica tutti sono mario monti http t co xptnz4x7 via linkiesta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XifL5FgKrQwl"
      },
      "source": [
        "Let's have a closer look at the tokenized sequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Apr3ZqnhrQwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84207270-7691-4d5b-d4bd-8efb2c37ad8a"
      },
      "source": [
        "seq_lens = [len(s) for s in sequences]\n",
        "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
        "print(\"max length: %d\" % max(seq_lens))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average length: 16.0\n",
            "max length: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "U6Hp4pXwrQwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "08bb6b38-8bfd-4d75-892d-0e21b0601283"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(seq_lens, bins=50);"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiV0lEQVR4nO3de3BU9f3/8VeuG26bGCC7pJCANyBCoAZJdrTWQkqgGQZL/kDLYGwZGNOFEVIppIOAYBuGdkRxAjgtJXZGROkUHUCRECRMJeESZIxgM8DEJhY2aXWSQDQXyPn94S/7dblIFgL72eX5mDkz2XM+m32/5wPDi8+eS5hlWZYAAAAMEh7oAgAAAC5HQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGCcy0AXciM7OTp09e1b9+vVTWFhYoMsBAADdYFmWzp8/r8TERIWHf/8aSVAGlLNnz2rIkCGBLgMAANyAuro6DR48+HvHBGVA6devn6RvG7Tb7QGuBgAAdEdzc7OGDBni/Xf8+wRlQOn6WsdutxNQAAAIMt05PYOTZAEAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwjl8BZcWKFQoLC/PZRowY4T3e2toqt9ut/v37q2/fvsrJyVF9fb3P76itrVV2drZ69+6thIQELVq0SBcvXuyZbgAAQEjw+2nGDzzwgPbu3ft/vyDy/37FwoULtWvXLm3btk2xsbGaN2+epk+fro8++kiSdOnSJWVnZ8vpdOrgwYM6d+6cnnrqKUVFRekPf/hDD7QDAABCgd8BJTIyUk6n84r9TU1N2rRpk7Zs2aIJEyZIkjZv3qyRI0eqoqJCGRkZ2rNnj06ePKm9e/fK4XBo7NixWrVqlRYvXqwVK1YoOjr65jsCcEcYumTXdcd8vjr7NlQC4FbwO6CcOnVKiYmJiomJkcvlUmFhoZKSklRZWamOjg5lZmZ6x44YMUJJSUkqLy9XRkaGysvLNXr0aDkcDu+YrKws5eXl6cSJE/rhD3941c9sa2tTW1ub93Vzc7O/ZQMIIt0JHwBCm1/noKSnp6u4uFi7d+/Whg0bVFNTox/96Ec6f/68PB6PoqOjFRcX5/Meh8Mhj8cjSfJ4PD7hpOt417FrKSwsVGxsrHcbMmSIP2UDAIAg49cKypQpU7w/p6amKj09XcnJyXr77bfVq1evHi+uS0FBgfLz872vm5ubCSkAAISwm7rMOC4uTvfff79Onz4tp9Op9vZ2NTY2+oypr6/3nrPidDqvuKqn6/XVzmvpYrPZZLfbfTYAABC6biqgXLhwQWfOnNGgQYOUlpamqKgolZaWeo9XV1ertrZWLpdLkuRyuVRVVaWGhgbvmJKSEtntdqWkpNxMKQAAIIT49RXPc889p6lTpyo5OVlnz57V8uXLFRERoSeffFKxsbGaPXu28vPzFR8fL7vdrvnz58vlcikjI0OSNGnSJKWkpGjWrFlas2aNPB6Pli5dKrfbLZvNdksaBAAAwcevgPLFF1/oySef1JdffqmBAwfqkUceUUVFhQYOHChJWrt2rcLDw5WTk6O2tjZlZWVp/fr13vdHRERo586dysvLk8vlUp8+fZSbm6uVK1f2bFcAACCohVmWZQW6CH81NzcrNjZWTU1NnI8ChKCeusyY+6AAZvHn32+exQMAAIxDQAEAAMbx+06yAHAt3H4eQE9hBQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA43agMQsrhxHBC8WEEBAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGiQx0AQCCw9AluwJdAoA7CCsoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOz+IBQlx3nqHz+ers21AJAHQfKygAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHG4URtgKG6wBuBOdlMrKKtXr1ZYWJgWLFjg3dfa2iq3263+/furb9++ysnJUX19vc/7amtrlZ2drd69eyshIUGLFi3SxYsXb6YUAAAQQm44oBw5ckSvvfaaUlNTffYvXLhQO3bs0LZt21RWVqazZ89q+vTp3uOXLl1Sdna22tvbdfDgQb3++usqLi7WsmXLbrwLAAAQUm7oK54LFy5o5syZ+vOf/6wXX3zRu7+pqUmbNm3Sli1bNGHCBEnS5s2bNXLkSFVUVCgjI0N79uzRyZMntXfvXjkcDo0dO1arVq3S4sWLtWLFCkVHR/dMZwC6rTtfJwHA7XRDKyhut1vZ2dnKzMz02V9ZWamOjg6f/SNGjFBSUpLKy8slSeXl5Ro9erQcDod3TFZWlpqbm3XixImrfl5bW5uam5t9NgAAELr8XkHZunWrjh07piNHjlxxzOPxKDo6WnFxcT77HQ6HPB6Pd8x3w0nX8a5jV1NYWKgXXnjB31IBAECQ8msFpa6uTs8++6zeeOMNxcTE3KqarlBQUKCmpibvVldXd9s+GwAA3H5+BZTKyko1NDTowQcfVGRkpCIjI1VWVqZ169YpMjJSDodD7e3tamxs9HlffX29nE6nJMnpdF5xVU/X664xl7PZbLLb7T4bAAAIXX4FlIkTJ6qqqkrHjx/3buPGjdPMmTO9P0dFRam0tNT7nurqatXW1srlckmSXC6Xqqqq1NDQ4B1TUlIiu92ulJSUHmoLAAAEM7/OQenXr59GjRrls69Pnz7q37+/d//s2bOVn5+v+Ph42e12zZ8/Xy6XSxkZGZKkSZMmKSUlRbNmzdKaNWvk8Xi0dOlSud1u2Wy2HmoLAAAEsx6/k+zatWsVHh6unJwctbW1KSsrS+vXr/cej4iI0M6dO5WXlyeXy6U+ffooNzdXK1eu7OlSAABAkLrpgLJ//36f1zExMSoqKlJRUdE135OcnKz33nvvZj8aAACEKB4WCAAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4N/00YwD+G7pkV6BLAACjsYICAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOPwLB4Ad7TuPBfp89XZt6ESAN/FCgoAADAOAQUAABiHr3iAHtadrwwAAN+PFRQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMaJDHQBQDAZumRXoEsAgDuCXysoGzZsUGpqqux2u+x2u1wul95//33v8dbWVrndbvXv3199+/ZVTk6O6uvrfX5HbW2tsrOz1bt3byUkJGjRokW6ePFiz3QDAABCgl8BZfDgwVq9erUqKyt19OhRTZgwQdOmTdOJEyckSQsXLtSOHTu0bds2lZWV6ezZs5o+fbr3/ZcuXVJ2drba29t18OBBvf766youLtayZct6tisAABDU/PqKZ+rUqT6vf//732vDhg2qqKjQ4MGDtWnTJm3ZskUTJkyQJG3evFkjR45URUWFMjIytGfPHp08eVJ79+6Vw+HQ2LFjtWrVKi1evFgrVqxQdHR0z3UGAACC1g2fJHvp0iVt3bpVLS0tcrlcqqysVEdHhzIzM71jRowYoaSkJJWXl0uSysvLNXr0aDkcDu+YrKwsNTc3e1dhrqatrU3Nzc0+GwAACF1+B5Sqqir17dtXNptNzzzzjLZv366UlBR5PB5FR0crLi7OZ7zD4ZDH45EkeTwen3DSdbzr2LUUFhYqNjbWuw0ZMsTfsgEAQBDxO6AMHz5cx48f16FDh5SXl6fc3FydPHnyVtTmVVBQoKamJu9WV1d3Sz8PAAAElt+XGUdHR+vee++VJKWlpenIkSN65ZVXNGPGDLW3t6uxsdFnFaW+vl5Op1OS5HQ6dfjwYZ/f13WVT9eYq7HZbLLZbP6WCgAAgtRN36its7NTbW1tSktLU1RUlEpLS73HqqurVVtbK5fLJUlyuVyqqqpSQ0ODd0xJSYnsdrtSUlJuthQAABAi/FpBKSgo0JQpU5SUlKTz589ry5Yt2r9/vz744APFxsZq9uzZys/PV3x8vOx2u+bPny+Xy6WMjAxJ0qRJk5SSkqJZs2ZpzZo18ng8Wrp0qdxuNyskAADAy6+A0tDQoKeeekrnzp1TbGysUlNT9cEHH+inP/2pJGnt2rUKDw9XTk6O2tralJWVpfXr13vfHxERoZ07dyovL08ul0t9+vRRbm6uVq5c2bNdAQCAoOZXQNm0adP3Ho+JiVFRUZGKioquOSY5OVnvvfeePx8LAADuMDyLB3eE7jxD5/PV2behEgBAd/A0YwAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxuEqHhiNq28A4M7ECgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDjcBwVBrzv3SgEABBdWUAAAgHFYQQGAHsBdj4GexQoKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGMevgFJYWKiHHnpI/fr1U0JCgh5//HFVV1f7jGltbZXb7Vb//v3Vt29f5eTkqL6+3mdMbW2tsrOz1bt3byUkJGjRokW6ePHizXcDAABCgl8BpaysTG63WxUVFSopKVFHR4cmTZqklpYW75iFCxdqx44d2rZtm8rKynT27FlNnz7de/zSpUvKzs5We3u7Dh48qNdff13FxcVatmxZz3UFAACCWqQ/g3fv3u3zuri4WAkJCaqsrNSjjz6qpqYmbdq0SVu2bNGECRMkSZs3b9bIkSNVUVGhjIwM7dmzRydPntTevXvlcDg0duxYrVq1SosXL9aKFSsUHR3dc90BAICgdFPnoDQ1NUmS4uPjJUmVlZXq6OhQZmamd8yIESOUlJSk8vJySVJ5eblGjx4th8PhHZOVlaXm5madOHHiqp/T1tam5uZmnw0AAIQuv1ZQvquzs1MLFizQww8/rFGjRkmSPB6PoqOjFRcX5zPW4XDI4/F4x3w3nHQd7zp2NYWFhXrhhRdutFQYauiSXYEuAQBgqBteQXG73fr000+1devWnqznqgoKCtTU1OTd6urqbvlnAgCAwLmhFZR58+Zp586dOnDggAYPHuzd73Q61d7ersbGRp9VlPr6ejmdTu+Yw4cP+/y+rqt8usZczmazyWaz3UipAAAgCPm1gmJZlubNm6ft27dr3759GjZsmM/xtLQ0RUVFqbS01LuvurpatbW1crlckiSXy6Wqqio1NDR4x5SUlMhutyslJeVmegEAACHCrxUUt9utLVu26N1331W/fv2854zExsaqV69eio2N1ezZs5Wfn6/4+HjZ7XbNnz9fLpdLGRkZkqRJkyYpJSVFs2bN0po1a+TxeLR06VK53W5WSQAAgCQ/A8qGDRskSY899pjP/s2bN+vpp5+WJK1du1bh4eHKyclRW1ubsrKytH79eu/YiIgI7dy5U3l5eXK5XOrTp49yc3O1cuXKm+sEAACEDL8CimVZ1x0TExOjoqIiFRUVXXNMcnKy3nvvPX8+GgAA3EF4Fg8AADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwTmSgCwCAO8XQJbuuO+bz1dm3oRLAfKygAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADG4UZt8Bs3mwIA3GqsoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA5X8cBHd67QAQDgVmMFBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOFxmfAfhEmIAQLBgBQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIc7yYYI7hILAAglrKAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHy4wBwCDduWXA56uzb0MlQGCxggIAAIxDQAEAAMbxO6AcOHBAU6dOVWJiosLCwvTOO+/4HLcsS8uWLdOgQYPUq1cvZWZm6tSpUz5jvvrqK82cOVN2u11xcXGaPXu2Lly4cFONAACA0OF3QGlpadGYMWNUVFR01eNr1qzRunXrtHHjRh06dEh9+vRRVlaWWltbvWNmzpypEydOqKSkRDt37tSBAwc0d+7cG+8CAACEFL9Pkp0yZYqmTJly1WOWZenll1/W0qVLNW3aNEnS3/72NzkcDr3zzjt64okn9Nlnn2n37t06cuSIxo0bJ0l69dVX9bOf/Ux/+tOflJiYeBPtAACAUNCj56DU1NTI4/EoMzPTuy82Nlbp6ekqLy+XJJWXlysuLs4bTiQpMzNT4eHhOnTo0FV/b1tbm5qbm302AAAQuno0oHg8HkmSw+Hw2e9wOLzHPB6PEhISfI5HRkYqPj7eO+ZyhYWFio2N9W5DhgzpybIBAIBhguIqnoKCAjU1NXm3urq6QJcEAABuoR69UZvT6ZQk1dfXa9CgQd799fX1Gjt2rHdMQ0ODz/suXryor776yvv+y9lsNtlstp4s1RjclAkAgCv16ArKsGHD5HQ6VVpa6t3X3NysQ4cOyeVySZJcLpcaGxtVWVnpHbNv3z51dnYqPT29J8sBAABByu8VlAsXLuj06dPe1zU1NTp+/Lji4+OVlJSkBQsW6MUXX9R9992nYcOG6fnnn1diYqIef/xxSdLIkSM1efJkzZkzRxs3blRHR4fmzZunJ554git4AACApBsIKEePHtVPfvIT7+v8/HxJUm5uroqLi/Xb3/5WLS0tmjt3rhobG/XII49o9+7diomJ8b7njTfe0Lx58zRx4kSFh4crJydH69at64F2AABAKPA7oDz22GOyLOuax8PCwrRy5UqtXLnymmPi4+O1ZcsWfz8aAADcIYLiKh4AAHBnIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGiQx0AaFs6JJdgS4BAICgxAoKAAAwDgEFAAAYh4ACAACMQ0ABAADG4SRZAAgy3TkB//PV2behEuDWYQUFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA40QGuoBgNXTJrkCXAABAyCKgAMAdqjv/0fp8dfZtqAS4El/xAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDlfxAACuiSt9ECgBXUEpKirS0KFDFRMTo/T0dB0+fDiQ5QAAAEMELKC89dZbys/P1/Lly3Xs2DGNGTNGWVlZamhoCFRJAADAEAH7iuell17SnDlz9Mtf/lKStHHjRu3atUt//etftWTJkkCVBQAwGF853TkCElDa29tVWVmpgoIC777w8HBlZmaqvLz8ivFtbW1qa2vzvm5qapIkNTc33/pir6Gz7evb9lnd6fN21tMd1Hx7UPPtQc3fL2nhtuuO+fSFrB75rO7UHMh/G/D9uubGsqzrD7YC4D//+Y8lyTp48KDP/kWLFlnjx4+/Yvzy5cstSWxsbGxsbGwhsNXV1V03KwTFVTwFBQXKz8/3vu7s7NRXX32l/v37KywsrEc/q7m5WUOGDFFdXZ3sdnuP/m4T0F/wC/Ue6S/4hXqPod6fdOt6tCxL58+fV2Ji4nXHBiSgDBgwQBEREaqvr/fZX19fL6fTecV4m80mm83msy8uLu5Wlii73R6yf/Ak+gsFod4j/QW/UO8x1PuTbk2PsbGx3RoXkKt4oqOjlZaWptLSUu++zs5OlZaWyuVyBaIkAABgkIB9xZOfn6/c3FyNGzdO48eP18svv6yWlhbvVT0AAODOFbCAMmPGDP33v//VsmXL5PF4NHbsWO3evVsOhyNQJUn69uuk5cuXX/GVUqigv+AX6j3SX/AL9R5DvT/JjB7DLKs71/oAAADcPjwsEAAAGIeAAgAAjENAAQAAxiGgAAAA4xBQvqOoqEhDhw5VTEyM0tPTdfjw4UCX1GNWrFihsLAwn23EiBGBLuuGHThwQFOnTlViYqLCwsL0zjvv+By3LEvLli3ToEGD1KtXL2VmZurUqVOBKfYGXK+/p59++or5nDx5cmCKvQGFhYV66KGH1K9fPyUkJOjxxx9XdXW1z5jW1la53W71799fffv2VU5OzhU3dzRZd3p87LHHrpjHZ555JkAV+2fDhg1KTU313sjL5XLp/fff9x4P9vmTrt9jMM/f5VavXq2wsDAtWLDAuy/Qc0hA+f/eeust5efna/ny5Tp27JjGjBmjrKwsNTQ0BLq0HvPAAw/o3Llz3u2f//xnoEu6YS0tLRozZoyKioquenzNmjVat26dNm7cqEOHDqlPnz7KyspSa2vrba70xlyvP0maPHmyz3y++eabt7HCm1NWVia3262KigqVlJSoo6NDkyZNUktLi3fMwoULtWPHDm3btk1lZWU6e/aspk+fHsCq/dOdHiVpzpw5PvO4Zs2aAFXsn8GDB2v16tWqrKzU0aNHNWHCBE2bNk0nTpyQFPzzJ12/Ryl45++7jhw5otdee02pqak++wM+hz3y9L8QMH78eMvtdntfX7p0yUpMTLQKCwsDWFXPWb58uTVmzJhAl3FLSLK2b9/ufd3Z2Wk5nU7rj3/8o3dfY2OjZbPZrDfffDMAFd6cy/uzLMvKzc21pk2bFpB6boWGhgZLklVWVmZZ1rfzFRUVZW3bts075rPPPrMkWeXl5YEq86Zc3qNlWdaPf/xj69lnnw1cUT3srrvusv7yl7+E5Px16erRskJj/s6fP2/dd999VklJiU8/JswhKyiS2tvbVVlZqczMTO++8PBwZWZmqry8PICV9axTp04pMTFRd999t2bOnKna2tpAl3RL1NTUyOPx+MxnbGys0tPTQ2o+9+/fr4SEBA0fPlx5eXn68ssvA13SDWtqapIkxcfHS5IqKyvV0dHhM4cjRoxQUlJS0M7h5T12eeONNzRgwACNGjVKBQUF+vrrrwNR3k25dOmStm7dqpaWFrlcrpCcv8t77BLs8+d2u5Wdne0zV5IZfweD4mnGt9r//vc/Xbp06Yq72DocDv3rX/8KUFU9Kz09XcXFxRo+fLjOnTunF154QT/60Y/06aefql+/foEur0d5PB5Juup8dh0LdpMnT9b06dM1bNgwnTlzRr/73e80ZcoUlZeXKyIiItDl+aWzs1MLFizQww8/rFGjRkn6dg6jo6OveChosM7h1XqUpF/84hdKTk5WYmKiPvnkEy1evFjV1dX6xz/+EcBqu6+qqkoul0utra3q27evtm/frpSUFB0/fjxk5u9aPUrBP39bt27VsWPHdOTIkSuOmfB3kIByh5gyZYr359TUVKWnpys5OVlvv/22Zs+eHcDKcCOeeOIJ78+jR49Wamqq7rnnHu3fv18TJ04MYGX+c7vd+vTTT4P6nKjruVaPc+fO9f48evRoDRo0SBMnTtSZM2d0zz333O4y/TZ8+HAdP35cTU1N+vvf/67c3FyVlZUFuqweda0eU1JSgnr+6urq9Oyzz6qkpEQxMTGBLueq+IpH0oABAxQREXHF2cn19fVyOp0BqurWiouL0/3336/Tp08HupQe1zVnd9J83n333RowYEDQzee8efO0c+dOffjhhxo8eLB3v9PpVHt7uxobG33GB+McXqvHq0lPT5ekoJnH6Oho3XvvvUpLS1NhYaHGjBmjV155JaTm71o9Xk0wzV9lZaUaGhr04IMPKjIyUpGRkSorK9O6desUGRkph8MR8DkkoOjbP4BpaWkqLS317uvs7FRpaanPd42h5MKFCzpz5owGDRoU6FJ63LBhw+R0On3ms7m5WYcOHQrZ+fziiy/05ZdfBs18WpalefPmafv27dq3b5+GDRvmczwtLU1RUVE+c1hdXa3a2tqgmcPr9Xg1x48fl6SgmcfLdXZ2qq2tLSTm71q6eryaYJq/iRMnqqqqSsePH/du48aN08yZM70/B3wOb8upuEFg69atls1ms4qLi62TJ09ac+fOteLi4iyPxxPo0nrEb37zG2v//v1WTU2N9dFHH1mZmZnWgAEDrIaGhkCXdkPOnz9vffzxx9bHH39sSbJeeukl6+OPP7b+/e9/W5ZlWatXr7bi4uKsd9991/rkk0+sadOmWcOGDbO++eabAFfePd/X3/nz563nnnvOKi8vt2pqaqy9e/daDz74oHXfffdZra2tgS69W/Ly8qzY2Fhr//791rlz57zb119/7R3zzDPPWElJSda+ffuso0ePWi6Xy3K5XAGs2j/X6/H06dPWypUrraNHj1o1NTXWu+++a919993Wo48+GuDKu2fJkiVWWVmZVVNTY33yySfWkiVLrLCwMGvPnj2WZQX//FnW9/cY7PN3NZdflRToOSSgfMerr75qJSUlWdHR0db48eOtioqKQJfUY2bMmGENGjTIio6Otn7wgx9YM2bMsE6fPh3osm7Yhx9+aEm6YsvNzbUs69tLjZ9//nnL4XBYNpvNmjhxolVdXR3Yov3wff19/fXX1qRJk6yBAwdaUVFRVnJysjVnzpygCtNX602StXnzZu+Yb775xvr1r39t3XXXXVbv3r2tn//859a5c+cCV7SfrtdjbW2t9eijj1rx8fGWzWaz7r33XmvRokVWU1NTYAvvpl/96ldWcnKyFR0dbQ0cONCaOHGiN5xYVvDPn2V9f4/BPn9Xc3lACfQchlmWZd2etRoAAIDu4RwUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIzz/wA7z+3q/dNprAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GfCRWAGirQwv"
      },
      "source": [
        "Let's zoom on the distribution of regular sized posts. The vast majority of the posts have less than 30 symbols:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5W6QRDcprQw0"
      },
      "source": [
        "Let's truncate and pad all the sequences to 25 symbols to build the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3DC-Ysi-rQw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75975fd7-f91d-4daa-aa6b-c01aea13a620"
      },
      "source": [
        "from keras.utils import pad_sequences\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "\n",
        "# pad sequences with 0s\n",
        "x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "x_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "\n",
        "print('Shape of data tensor:', x_train.shape)\n",
        "print('Shape of data test tensor:', x_test.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (7410, 25)\n",
            "Shape of data test tensor: (2000, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yij15CxGZxmE",
        "outputId": "d220aa24-ed22-423f-acf0-a6ed95b5a24e"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 557,   11, 1081,   14,   47,  651,   22, 6520, 4070,  111,   10,\n",
              "        904,   34,   33,   15,    1,    7,    5,    6, 6521,   47,  977,\n",
              "          0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "77rTAOV3rQw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4327e392-bc04-4e4c-ab0e-42e36c349a1f"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = train[\"opos\"]\n",
        "y_test = test[\"opos\"]\n",
        "\n",
        "y_train = to_categorical(np.asarray(y_train))\n",
        "print('Shape of label tensor:', y_train.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (7410, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSeAYSbF2ku4",
        "outputId": "b6c46239-50f6-4c3f-f5b8-33740112a23c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "oShKBBdVrQxD"
      },
      "source": [
        "### A simple supervised model in Keras\n",
        "\n",
        "The following computes a very simple model:\n",
        "\n",
        "<img src=\"https://m2dsupsdlclass.github.io/lectures-labs/slides/06_deep_nlp/images/fasttext.svg\" style=\"width: 600px;\" />\n",
        "\n",
        "- Build an embedding layer mapping each word to a vector representation\n",
        "- Compute the vector representation of all words in each sequence and average them\n",
        "- Add a dense layer to output 20 classes (+ softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6lnA30CarQxE"
      },
      "source": [
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, Embedding\n",
        "from keras.models import Model\n",
        "\n",
        "EMBEDDING_DIM = 50\n",
        "N_CLASSES = 2\n",
        "\n",
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)(sequence_input)\n",
        "\n",
        "average = GlobalAveragePooling1D()(embedded_sequences)\n",
        "predictions = Dense(N_CLASSES, activation='softmax')(average)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "59y4Uv5UrQxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2088726b-7d20-42f1-e307-c83299f26bb1"
      },
      "source": [
        "history=model.fit(x_train, y_train, validation_split=0.1,\n",
        "          epochs=10, batch_size=128, verbose=2)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 - 11s - loss: 0.6386 - acc: 0.7138 - val_loss: 0.5420 - val_acc: 0.7989 - 11s/epoch - 213ms/step\n",
            "Epoch 2/10\n",
            "53/53 - 5s - loss: 0.5829 - acc: 0.7149 - val_loss: 0.5142 - val_acc: 0.7989 - 5s/epoch - 90ms/step\n",
            "Epoch 3/10\n",
            "53/53 - 4s - loss: 0.5496 - acc: 0.7154 - val_loss: 0.5126 - val_acc: 0.8003 - 4s/epoch - 66ms/step\n",
            "Epoch 4/10\n",
            "53/53 - 3s - loss: 0.5167 - acc: 0.7239 - val_loss: 0.5243 - val_acc: 0.8165 - 3s/epoch - 54ms/step\n",
            "Epoch 5/10\n",
            "53/53 - 2s - loss: 0.4827 - acc: 0.7575 - val_loss: 0.5124 - val_acc: 0.8016 - 2s/epoch - 29ms/step\n",
            "Epoch 6/10\n",
            "53/53 - 1s - loss: 0.4450 - acc: 0.7860 - val_loss: 0.5081 - val_acc: 0.7908 - 1s/epoch - 21ms/step\n",
            "Epoch 7/10\n",
            "53/53 - 1s - loss: 0.4043 - acc: 0.8217 - val_loss: 0.5065 - val_acc: 0.7814 - 1s/epoch - 20ms/step\n",
            "Epoch 8/10\n",
            "53/53 - 1s - loss: 0.3635 - acc: 0.8572 - val_loss: 0.5167 - val_acc: 0.7706 - 929ms/epoch - 18ms/step\n",
            "Epoch 9/10\n",
            "53/53 - 1s - loss: 0.3249 - acc: 0.8871 - val_loss: 0.5148 - val_acc: 0.7638 - 925ms/epoch - 17ms/step\n",
            "Epoch 10/10\n",
            "53/53 - 1s - loss: 0.2896 - acc: 0.9060 - val_loss: 0.5092 - val_acc: 0.7625 - 759ms/epoch - 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PG7mBeqJrQxV"
      },
      "source": [
        "**Exercice**\n",
        " - compute model evaluation on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation"
      ],
      "metadata": {
        "id": "oEgmwVLQWrEX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "K-MqP7zSrQxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f3d48e-5a80-4e1f-f8b9-08d7b2808fa7"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "\n",
        "test_classes = np.argmax(output_test, axis=-1)\n",
        "\n",
        "print(test_classes)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"test accuracy:\", accuracy_score(test_classes,y_test))\n",
        "print(\"test precision:\", precision_score(test_classes,y_test,average='macro'))\n",
        "print(\"test recall:\", recall_score(test_classes,y_test,average='macro'))\n",
        "print(\"test F1:\", f1_score(test_classes,y_test,average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewqzhPwAlzXl",
        "outputId": "caa0871e-3599-4a5f-83ee-42f584aa67f1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 0.841\n",
            "test precision: 0.6242552956751986\n",
            "test recall: 0.7316939890710382\n",
            "test F1: 0.6496863701559226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Complex Models"
      ],
      "metadata": {
        "id": "n57jWkW7Wwep"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ecciDY9arQxe"
      },
      "source": [
        "### Building more complex models\n",
        "\n",
        "**Exercise**\n",
        "- From the previous template, build more complex models using:\n",
        "  - 1d convolution and 1d maxpooling. Note that you will still need a GloabalAveragePooling or Flatten after the convolutions\n",
        "  - Recurrent neural networks through LSTM (you will need to reduce sequence length before)\n",
        "  \n",
        "  \n",
        "<img src=\"https://m2dsupsdlclass.github.io/lectures-labs/slides/06_deep_nlp/images/unrolled_rnn_one_output_2.svg\" style=\"width: 600px;\" />\n",
        "\n",
        "**Bonus**\n",
        "- You may try different architectures with:\n",
        "  - more intermediate layers, combination of dense, conv, recurrent\n",
        "  - different recurrent (GRU, RNN)\n",
        "  - bidirectional LSTMs\n",
        "\n",
        "Note: The goal is to build working models rather than getting better test accuracy. To achieve much better results, we'd need more computation time and data quantity. Build your model, and verify that they converge to OK results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XXisPg6ND8Y"
      },
      "source": [
        "# solutions lstm.py\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, Embedding, Flatten, Dense, Dropout\n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YuumzzWZrQxf"
      },
      "source": [
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True) (sequence_input)\n",
        "\n",
        "# LSTM layer with a hidden size of 64\n",
        "x = LSTM(64,dropout=0.2)(embedded_sequences)\n",
        "x = Dense(30) (x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# You will get large speedups with these models by using a GPU\n",
        "# The model might take a lot of time to converge, and even more\n",
        "# if you add dropout (needed to prevent overfitting)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdrNvZ5D8ojO",
        "outputId": "26a4cdc7-d484-44a5-f259-118a11c15f73"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                93440     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                1950      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6095452 (23.25 MB)\n",
            "Trainable params: 6095452 (23.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jtm2uIB30v0",
        "outputId": "5ace3245-0b1a-4b1d-f05b-67f648ee4a32"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=4, validation_split=0.1,\n",
        "          batch_size=128)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "53/53 [==============================] - 13s 159ms/step - loss: 0.5966 - acc: 0.7066 - val_loss: 0.4742 - val_acc: 0.7922\n",
            "Epoch 2/4\n",
            "53/53 [==============================] - 5s 91ms/step - loss: 0.3911 - acc: 0.8265 - val_loss: 0.6766 - val_acc: 0.6680\n",
            "Epoch 3/4\n",
            "53/53 [==============================] - 3s 63ms/step - loss: 0.1577 - acc: 0.9436 - val_loss: 0.7374 - val_acc: 0.7382\n",
            "Epoch 4/4\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0696 - acc: 0.9774 - val_loss: 0.7651 - val_acc: 0.7409\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b3d41c7f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkBlX7d-3y-p",
        "outputId": "58a63653-572a-41ef-f012-f09c45b8dd99"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "print(\"test accuracy:\", accuracy_score(test_casses,y_test))\n",
        "print(\"test precision:\", precision_score(test_casses,y_test,average='macro'))\n",
        "print(\"test recall:\", recall_score(test_casses,y_test,average='macro'))\n",
        "print(\"test F1:\", f1_score(test_casses,y_test,average='macro'))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "test accuracy: 0.782\n",
            "test precision: 0.6107954545454546\n",
            "test recall: 0.6171957054498775\n",
            "test F1: 0.6137491141034728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ewXMxJv5rQxh"
      },
      "source": [
        "# %load solutions/conv1d.py\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True) (sequence_input)\n",
        "\n",
        "# A 1D convolution with 128 output channels\n",
        "x = Conv1D(128, 2, activation='relu')(embedded_sequences)\n",
        "# MaxPool divides the length of the sequence by 5\n",
        "x = MaxPooling1D(2)(x)\n",
        "# A 1D convolution with 64 output channels\n",
        "x = Conv1D(64, 2, activation='relu')(x)\n",
        "# MaxPool divides the length of the sequence by 5\n",
        "x = MaxPooling1D(2)(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDTEH4J099qy",
        "outputId": "3270552d-3fb0-4a35-f5be-a332364c7f15"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 24, 128)           76928     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 12, 128)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            16448     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 5, 64)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 320)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 642       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6094018 (23.25 MB)\n",
            "Trainable params: 6094018 (23.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GicNxZ65Vj_",
        "outputId": "f1bbb78b-4e38-4e5d-af72-ee2f24604a22"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=4, validation_split=0.1,\n",
        "          batch_size=128)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "53/53 [==============================] - 14s 113ms/step - loss: 0.5903 - acc: 0.7141 - val_loss: 0.5193 - val_acc: 0.7989\n",
            "Epoch 2/4\n",
            "53/53 [==============================] - 3s 59ms/step - loss: 0.4489 - acc: 0.7772 - val_loss: 0.4981 - val_acc: 0.7395\n",
            "Epoch 3/4\n",
            "53/53 [==============================] - 3s 56ms/step - loss: 0.1512 - acc: 0.9445 - val_loss: 0.6739 - val_acc: 0.6842\n",
            "Epoch 4/4\n",
            "53/53 [==============================] - 3s 45ms/step - loss: 0.0263 - acc: 0.9951 - val_loss: 0.7384 - val_acc: 0.7152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b3d37ea7f70>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiNX-sUr5WJb",
        "outputId": "9bf89859-69c3-4ce0-bc74-cece4dd230e2"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "print(\"test accuracy:\", accuracy_score(test_casses,y_test))\n",
        "print(\"test precision:\", precision_score(test_casses,y_test,average='macro'))\n",
        "print(\"test recall:\", recall_score(test_casses,y_test,average='macro'))\n",
        "print(\"test F1:\", f1_score(test_casses,y_test,average='macro'))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step\n",
            "test accuracy: 0.7745\n",
            "test precision: 0.6129468225948809\n",
            "test recall: 0.6121965837578663\n",
            "test F1: 0.6125680851456801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2mbEd2MMyde"
      },
      "source": [
        "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
        "\n",
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True) (sequence_input)\n",
        "\n",
        "# 1D convolution with 64 output channels\n",
        "x = Conv1D(128, 2)(embedded_sequences)\n",
        "# MaxPool divides the length of the sequence by 5\n",
        "x = MaxPooling1D(2)(x)\n",
        "# LSTM layer with a hidden size of 64\n",
        "x = LSTM(64)(x)\n",
        "x = Dense(30) (x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuEZxr2M-NX5",
        "outputId": "8db31e36-4e7d-4a3c-e98a-361da9499407"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 24, 128)           76928     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 12, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                1950      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6128348 (23.38 MB)\n",
            "Trainable params: 6128348 (23.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "d_DgldjvrQxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c60b721-0423-4a5e-a378-c851277ab7f0"
      },
      "source": [
        "model.fit(x_train, y_train, validation_split=0.1,\n",
        "          epochs=5, batch_size=128)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "53/53 [==============================] - 9s 109ms/step - loss: 0.5886 - acc: 0.7176 - val_loss: 0.4907 - val_acc: 0.8057\n",
            "Epoch 2/5\n",
            "53/53 [==============================] - 3s 67ms/step - loss: 0.3688 - acc: 0.8358 - val_loss: 0.6896 - val_acc: 0.6653\n",
            "Epoch 3/5\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.1094 - acc: 0.9601 - val_loss: 1.0548 - val_acc: 0.6491\n",
            "Epoch 4/5\n",
            "53/53 [==============================] - 2s 48ms/step - loss: 0.0275 - acc: 0.9918 - val_loss: 0.8924 - val_acc: 0.7611\n",
            "Epoch 5/5\n",
            "53/53 [==============================] - 2s 37ms/step - loss: 0.0135 - acc: 0.9958 - val_loss: 1.1993 - val_acc: 0.6829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b3d37e4f7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Nu2QveWRtQNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599110f1-b6ec-4194-c045-b37d4652c56c"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "print(\"test accuracy:\", accuracy_score(test_casses,y_test))\n",
        "print(\"test precision:\", precision_score(test_casses,y_test,average='macro'))\n",
        "print(\"test recall:\", recall_score(test_casses,y_test,average='macro'))\n",
        "print(\"test F1:\", f1_score(test_casses,y_test,average='macro'))\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 2ms/step\n",
            "test accuracy: 0.7695\n",
            "test precision: 0.6423074801412181\n",
            "test recall: 0.6237529438395613\n",
            "test F1: 0.631107776944236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqO2CMeywZyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b6ac17-c6ab-4ace-b875-fd05d7edc0a5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix= confusion_matrix(test_casses, y_test)\n",
        "print(confusion_matrix)\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1382  195]\n",
            " [ 266  157]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKCXV0Fs1Iwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53551462-9cd8-404c-adec-bd282063824d"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_casses, y_test))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86      1577\n",
            "           1       0.45      0.37      0.41       423\n",
            "\n",
            "    accuracy                           0.77      2000\n",
            "   macro avg       0.64      0.62      0.63      2000\n",
            "weighted avg       0.76      0.77      0.76      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Yg5PujZArQxp"
      },
      "source": [
        "### Loading pre-trained embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDwTwcG3QZiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae7ae6b-6f7c-4a09-9d06-e85096d15dd2"
      },
      "source": [
        "import os.path as op\n",
        "import gzip\n",
        "import shutil\n",
        "from urllib.request import urlretrieve\n",
        "# Get pretrained FastText Embeddings\n",
        "URL_REPRESENTATIONS = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz\"\n",
        "ZIP_REPRESENTATIONS = \"cc.it.300.vec.gz\"\n",
        "FILE_REPRESENTATIONS = \"cc.it.300.vec\"\n",
        "\n",
        "if not op.exists(ZIP_REPRESENTATIONS):\n",
        "    print('Downloading from %s to %s...' % (URL_REPRESENTATIONS, ZIP_REPRESENTATIONS))\n",
        "    urlretrieve(URL_REPRESENTATIONS, './' + ZIP_REPRESENTATIONS)\n",
        "\n",
        "with gzip.open(ZIP_REPRESENTATIONS, 'rb') as f_in:\n",
        "    with open(FILE_REPRESENTATIONS, 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz to cc.it.300.vec.gz...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "s2ruhdN7rQxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bea507e-1dd5-441a-bfdd-61e3b245f043"
      },
      "source": [
        "embeddings_index = {}\n",
        "embeddings_vectors = []\n",
        "f = open('cc.it.300.vec', 'rb')\n",
        "\n",
        "word_idx = 0\n",
        "i = 0\n",
        "for line in f:\n",
        "    if i != 0:\n",
        "      values = line.decode('utf-8').split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = word_idx\n",
        "      embeddings_vectors.append(vector)\n",
        "      word_idx = word_idx + 1\n",
        "    i = i+1\n",
        "f.close()\n",
        "\n",
        "inv_index = {v: k for k, v in embeddings_index.items()}\n",
        "print(\"found %d different words in the file\" % word_idx)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 2000000 different words in the file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "155s4vaVrQxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae63a29f-e667-41c5-c5ec-5f5d7600e364"
      },
      "source": [
        "# Stack all embeddings in a large numpy array\n",
        "embeddings = np.vstack(embeddings_vectors)\n",
        "\n",
        "print(embeddings.shape)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GL_Hxg5RrQxv"
      },
      "source": [
        "def get_emb(word):\n",
        "    idx = embeddings_index.get(word)\n",
        "    if idx is None:\n",
        "        return None\n",
        "    else:\n",
        "        return embeddings[idx]"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TqiENnsQrQx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc677890-6660-4487-db0a-0c6a1e71715f"
      },
      "source": [
        "get_emb(\"ci\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.8300e-02, -5.6700e-02, -4.2840e-01, -8.7800e-02,  1.9370e-01,\n",
              "       -1.3990e-01, -5.3600e-02, -1.0140e-01,  3.3660e-01,  2.8670e-01,\n",
              "        1.0720e-01,  6.0500e-02,  4.0150e-01,  1.0830e-01,  6.1400e-02,\n",
              "        2.3900e-02,  9.8700e-02, -2.3500e-02, -3.1700e-02,  3.4000e-03,\n",
              "        1.3490e-01, -2.3930e-01, -1.1300e-02, -5.7200e-02,  1.2720e-01,\n",
              "       -6.2200e-02,  1.6000e-02,  8.6800e-02,  1.2330e-01,  2.2320e-01,\n",
              "        3.2500e-02, -6.3400e-02, -9.6000e-02, -5.5000e-03, -7.1200e-02,\n",
              "        3.0200e-02, -1.8740e-01, -3.7200e-02, -1.9600e-02,  9.5100e-02,\n",
              "        1.2500e-02,  1.1000e-02,  1.7210e-01, -1.6990e-01, -1.2660e-01,\n",
              "        6.0000e-02,  1.9790e-01,  9.4300e-02, -1.8730e-01,  1.2780e-01,\n",
              "       -7.6600e-02,  8.3000e-02,  5.2000e-03,  1.5920e-01,  3.4600e-02,\n",
              "       -1.7000e-01, -2.3270e-01,  1.3280e-01, -2.0480e-01, -7.5900e-02,\n",
              "        1.7250e-01,  1.8630e-01,  1.6310e-01, -4.7000e-02, -1.4840e-01,\n",
              "        2.4350e-01, -2.1800e-02,  2.1400e-02,  1.6900e-01, -4.4400e-02,\n",
              "        1.4590e-01, -1.0110e-01,  1.0380e-01,  4.6000e-03, -1.9600e-02,\n",
              "       -2.3900e-01, -2.7970e-01, -2.6870e-01,  5.3200e-02,  5.4400e-02,\n",
              "        1.6160e-01, -2.7460e-01, -2.8420e-01,  2.2940e-01, -4.7670e-01,\n",
              "        1.7370e-01, -2.0830e-01, -1.0540e-01,  1.7000e-01, -2.2890e-01,\n",
              "        1.7450e-01,  1.8360e-01,  1.2770e-01,  8.0400e-02, -1.0275e+00,\n",
              "       -2.0600e-02,  1.6790e-01,  6.3300e-02,  5.5590e-01, -1.4840e-01,\n",
              "        1.5130e-01, -4.4100e-02, -1.5600e-01,  1.1600e-01, -1.0580e-01,\n",
              "        3.8820e-01, -2.5400e-02,  1.7190e-01,  1.2420e-01, -1.9710e-01,\n",
              "        1.2310e-01,  4.3120e-01,  5.6270e-01,  1.5560e-01, -3.9800e-02,\n",
              "        2.2300e-02,  1.3850e-01,  1.6500e-01,  9.8500e-02,  7.9800e-02,\n",
              "        1.5620e-01, -4.1000e-02, -7.7700e-02, -9.7400e-02,  8.6000e-03,\n",
              "        1.9650e-01, -3.4920e-01,  7.5200e-02,  8.2200e-02,  9.1700e-01,\n",
              "       -1.6400e-02,  1.9550e-01, -2.8700e-02,  6.3200e-02,  5.3900e-02,\n",
              "       -1.0660e-01,  1.0860e-01,  2.2400e-02,  3.4960e-01,  7.7800e-02,\n",
              "        2.0510e-01, -1.2780e-01, -4.1000e-02,  6.0400e-02,  1.1750e-01,\n",
              "       -8.5400e-02,  8.3500e-02, -2.2240e-01, -6.3600e-02, -4.3000e-03,\n",
              "        1.0000e-01, -7.5600e-02, -1.0790e-01,  3.1750e-01, -1.3190e-01,\n",
              "        1.4870e-01,  2.5630e-01,  1.5440e-01,  1.4210e-01, -1.4050e-01,\n",
              "        1.4100e-02, -3.9100e-02, -6.2400e-02, -2.8500e-02,  1.7000e-02,\n",
              "       -2.0100e-02, -1.8740e-01,  2.0400e-01,  5.1900e-02,  2.1800e-02,\n",
              "       -3.3790e-01,  9.3800e-02,  2.2610e-01,  9.6100e-02, -5.8700e-02,\n",
              "       -6.7000e-03,  8.3700e-02,  2.2230e-01, -8.8900e-02,  1.4270e-01,\n",
              "       -1.9270e-01,  1.4190e-01,  6.0000e-04, -8.0700e-02, -1.3010e-01,\n",
              "       -3.1900e-02, -1.6600e-02, -4.2000e-03,  2.8820e-01, -1.5900e-02,\n",
              "        8.0600e-02, -7.1000e-03, -5.8100e-02,  1.8390e-01, -8.3200e-02,\n",
              "       -9.9100e-02,  7.5800e-02,  2.3270e-01, -5.9510e-01,  3.3000e-03,\n",
              "       -2.3460e-01, -2.8210e-01, -8.1000e-02, -2.5550e-01, -2.6800e-02,\n",
              "        9.3000e-02, -3.5620e-01,  1.1610e-01, -1.8400e-02, -5.0930e-01,\n",
              "       -1.6300e-01,  8.3700e-02,  2.1070e-01, -2.0350e-01,  2.9800e-02,\n",
              "        1.4930e-01, -1.0660e-01,  8.8800e-02,  3.3080e-01,  3.5600e-02,\n",
              "       -9.0000e-03,  2.3560e-01, -9.7600e-02,  7.1000e-03,  2.0650e-01,\n",
              "        1.9110e-01, -1.3100e-01,  4.1020e-01,  5.9200e-02,  2.8500e-02,\n",
              "       -1.1440e-01,  1.0540e-01, -1.0640e-01,  3.2600e-02, -1.7060e-01,\n",
              "       -2.0700e-02, -8.9700e-02,  3.7000e-03, -9.2500e-02, -1.4250e-01,\n",
              "       -1.9080e-01, -6.4000e-03, -3.2350e-01,  2.3570e-01, -4.4700e-02,\n",
              "       -8.2200e-02,  1.9360e-01, -1.9710e-01,  1.8440e-01,  5.0090e-01,\n",
              "       -2.2530e-01,  7.7300e-02, -4.2800e-02, -6.2200e-02, -9.4700e-02,\n",
              "       -3.4200e-02, -1.4450e-01,  1.8900e-01, -4.7620e-01, -3.3300e-02,\n",
              "       -5.1100e-02,  1.3050e-01, -1.3470e-01, -2.1500e-02,  1.9070e-01,\n",
              "        2.5120e-01,  1.1200e-02, -9.4300e-02,  1.4210e-01, -5.9100e-02,\n",
              "        2.6630e-01,  7.4100e-02,  1.3140e-01,  1.7600e-02,  7.7500e-02,\n",
              "       -1.0110e-01, -2.9340e-01, -9.0600e-02,  2.8300e-01,  4.2600e-02,\n",
              "       -2.1840e-01,  1.2450e-01,  1.0410e-01,  1.0400e-01,  1.4720e-01,\n",
              "        4.8400e-02,  4.3300e-02, -2.8700e-02,  5.3000e-02, -4.6800e-02,\n",
              "       -7.0700e-02,  1.3960e-01, -1.5540e-01, -3.1100e-02, -9.9000e-02,\n",
              "       -5.6700e-02,  1.2660e-01,  1.1140e-01, -8.5400e-02, -2.3900e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LrhTtGiLrQx-"
      },
      "source": [
        "### Finding most similar words\n",
        "\n",
        "**Exercice**\n",
        "\n",
        "Build a function to find most similar words, given a word as query:\n",
        "- lookup the vector for the query word in the Glove index;\n",
        "- compute the cosine similarity between a word embedding and all other words;\n",
        "- display the top 10 most similar words.\n",
        "\n",
        "**Bonus**\n",
        "\n",
        "Change your function so that it takes multiple words as input (by averaging them)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "-9dWPg2jrQx_"
      },
      "source": [
        "# %load solutions/most_similar.py\n",
        "def most_similar(words, topn=10):\n",
        "    query_emb = 0\n",
        "    # If we have a list of words instead of one word\n",
        "    # (bonus question)\n",
        "    if type(words) == list:\n",
        "        for word in words:\n",
        "            query_emb += get_emb(word)\n",
        "    else:\n",
        "        query_emb = get_emb(words)\n",
        "\n",
        "    #query_emb = query_emb / np.linalg.norm(query_emb)\n",
        "\n",
        "    # Large numpy vector with all similarities\n",
        "    # between emb and all other words\n",
        "    similarities = np.dot(embeddings, query_emb)\n",
        "\n",
        "    # topn most similar indexes\n",
        "    idxs = np.argsort(similarities)[::-1][:topn]\n",
        "\n",
        "    # pretty return with word and similarity\n",
        "    return [(inv_index[idx], similarities[idx]) for idx in idxs]\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tccMS4JirQyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9cbbdd-8755-4aaf-9426-5db6d31f1cc7"
      },
      "source": [
        "most_similar(\"cpu\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cpu', 7.150271),\n",
              " ('i7', 6.539628),\n",
              " ('i5', 5.7718916),\n",
              " ('R0', 5.4669394),\n",
              " ('CPU', 5.465336),\n",
              " ('gpu', 5.425723),\n",
              " ('ram', 5.3928967),\n",
              " ('kJ', 5.143676),\n",
              " ('nm', 5.0835543),\n",
              " ('gb', 4.7928314)]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "s1XAK3rQrQyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e6179e-4645-458a-f805-15ff25e857df"
      },
      "source": [
        "most_similar(\"mela\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mela', 2.3820162),\n",
              " ('uva', 1.885606),\n",
              " ('bt', 1.7568856),\n",
              " ('3g', 1.7126958),\n",
              " ('Tè', 1.7035183),\n",
              " ('mele', 1.5696958),\n",
              " ('pomo', 1.5258517),\n",
              " ('M8', 1.5124705),\n",
              " ('Mela', 1.4639683),\n",
              " ('yi', 1.4282726)]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DcH77x4HrQyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0fe111-49c6-40d7-d5a2-6c71e676a79c"
      },
      "source": [
        "most_similar(\"latte\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ml', 1.614389),\n",
              " ('tè', 1.5165406),\n",
              " ('té', 1.4574687),\n",
              " ('UHT', 1.4431446),\n",
              " ('µg', 1.3956451),\n",
              " ('latte', 1.3748871),\n",
              " ('mL', 1.3286628),\n",
              " ('pH', 1.1744329),\n",
              " ('soia', 1.1358578),\n",
              " ('Bf', 1.1308407)]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wPLE9E9ZrQys"
      },
      "source": [
        "### Using pre-trained embeddings in our model\n",
        "\n",
        "We want to use these pre-trained embeddings for transfer learning. This process is rather similar than transfer learning in image recognition: the features learnt on words might help us bootstrap the learning process, and increase performance if we don't have enough training data.\n",
        "- We initialize embedding matrix from the model with embeddings:\n",
        " - take all words from our 20 Newgroup vocabulary (`MAX_NB_WORDS = 20000`), and look up their embedding\n",
        " - place the Glove embedding at the corresponding index in the matrix\n",
        " - if the word is not in the vocabulary, we only place zeros in the matrix\n",
        "- We may fix these embeddings or fine-tune them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OgMfL-eZrQys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a152c8-9c66-4802-bc1f-3295c58dd5d3"
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "\n",
        "# prepare embedding matrix\n",
        "nb_words_in_matrix = 0\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NB_WORDS:\n",
        "        continue\n",
        "    embedding_vector = get_emb(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        nb_words_in_matrix = nb_words_in_matrix + 1\n",
        "\n",
        "print(\"added %d words in the embedding matrix\" % nb_words_in_matrix)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added 13368 words in the embedding matrix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHcT5YfajuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3f3b12-9e1e-452b-87a8-88192813443c"
      },
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "V93Ik4QWrQyv"
      },
      "source": [
        "Build a layer with pre-trained embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MhZZdW72rQyy"
      },
      "source": [
        "pretrained_embedding_layer = Embedding(\n",
        "    MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_SEQUENCE_LENGTH\n",
        ")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8Y7iUkbwrQzE"
      },
      "source": [
        "### A model with pre-trained Embeddings\n",
        "\n",
        "Average word embeddings pre-trained with Glove / Word2Vec usually works suprisingly well. However, when averaging more than `10-15` words, the resulting vector becomes too noisy and classification performance is degraded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gG9dWAhorQzH"
      },
      "source": [
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "emb = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH)(sequence_input)\n",
        "\n",
        "rec = LSTM(units=128,return_sequences = True)(emb)\n",
        "flat = Flatten()(rec)\n",
        "dense = Dense(200,activation='sigmoid') (flat)\n",
        "predictions = Dense(N_CLASSES, activation='softmax')(dense)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "\n",
        "# We don't want to fine-tune embeddings\n",
        "model.layers[1].trainable=False\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_eSJiYdd_q6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835e7465-ee6c-41ed-adfa-31cb9f0d4aba"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "#plot_model(model)\n",
        "model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 25, 128)           219648    \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 200)               640200    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6860250 (26.17 MB)\n",
            "Trainable params: 860250 (3.28 MB)\n",
            "Non-trainable params: 6000000 (22.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lMt5THcJrQza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f81d22-8498-45c8-9686-178cdd26122d"
      },
      "source": [
        "model.fit(x_train, y_train, validation_split=0.1,\n",
        "          epochs=10, batch_size=128)\n",
        "\n",
        "# Note, on this type of task, this technique will\n",
        "# degrade results as we train much less parameters\n",
        "# and we average a large number pre-trained embeddings.\n",
        "# You will notice much less overfitting then!\n",
        "# Using convolutions / LSTM will help\n",
        "# It is also advisable to treat seperately pre-trained\n",
        "# embeddings and words out of vocabulary."
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 [==============================] - 7s 21ms/step - loss: 0.5748 - acc: 0.7052 - val_loss: 0.5493 - val_acc: 0.7314\n",
            "Epoch 2/10\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5208 - acc: 0.7577 - val_loss: 0.6129 - val_acc: 0.6856\n",
            "Epoch 3/10\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.4981 - acc: 0.7706 - val_loss: 0.5272 - val_acc: 0.7652\n",
            "Epoch 4/10\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.4758 - acc: 0.7823 - val_loss: 0.5628 - val_acc: 0.7571\n",
            "Epoch 5/10\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.4556 - acc: 0.7932 - val_loss: 0.5133 - val_acc: 0.7625\n",
            "Epoch 6/10\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.4399 - acc: 0.8037 - val_loss: 0.7027 - val_acc: 0.6775\n",
            "Epoch 7/10\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.4147 - acc: 0.8160 - val_loss: 0.5510 - val_acc: 0.7571\n",
            "Epoch 8/10\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.3986 - acc: 0.8219 - val_loss: 0.4951 - val_acc: 0.7895\n",
            "Epoch 9/10\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.3862 - acc: 0.8309 - val_loss: 0.5279 - val_acc: 0.7787\n",
            "Epoch 10/10\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.3774 - acc: 0.8321 - val_loss: 0.6735 - val_acc: 0.6950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b3bfe72e2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WKZdqUlXHle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc517cc-4db4-4d7f-8c06-7545200fdcff"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "print(\"test accuracy:\", accuracy_score(test_casses,y_test))\n",
        "print(\"test precision:\", precision_score(test_casses,y_test,average='macro'))\n",
        "print(\"test recall:\", recall_score(test_casses,y_test,average='macro'))\n",
        "print(\"test F1:\", f1_score(test_casses,y_test,average='macro'))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 5ms/step\n",
            "test accuracy: 0.6705\n",
            "test precision: 0.6179804721977052\n",
            "test recall: 0.575979018067775\n",
            "test F1: 0.5710516492217907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_Q-27vx1rQzq"
      },
      "source": [
        "### Reality check\n",
        "\n",
        "On small/medium datasets, simpler classification methods usually perform better, and are much more efficient to compute. Here are two resources to go further:\n",
        "- Naive Bayes approach, using scikit-learn http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
        "- Alec Radford (OpenAI) gave a very interesting presentation, showing that you need a VERY large dataset to have real gains from GRU/LSTM in text classification https://www.slideshare.net/odsc/alec-radfordodsc-presentation\n",
        "\n",
        "However, when looking at features, one can see that classification using simple methods isn't very robust, and won't generalize well to slightly different domains (e.g. forum posts => emails)\n",
        "\n",
        "Note: Implementation in Keras for text is very slow due to python overhead and lack of hashing techniques. The fastText implementation https://github.com/facebookresearch/fasttext is much, much faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "8YPxcEvxrQzq"
      },
      "source": [
        "## Going further\n",
        "\n",
        "- Compare pre-trained embeddings vs specifically trained embeddings\n",
        "- Train your own wordvectors in any language using [gensim's word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
        "- Check [Keras Examples](https://github.com/fchollet/keras/tree/master/examples) on `imdb` sentiment analysis\n",
        "- Use GLOVE over Gensim and give it a try on the classification example in its repository.\n",
        "- Try Different pre-processing operations using SpaCy or Ekphrasis (see example below), i.e. stopword removal, stemming, etc.\n"
      ]
    }
  ]
}