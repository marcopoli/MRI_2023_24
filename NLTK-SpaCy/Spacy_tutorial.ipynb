{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iBziwmskddV",
        "outputId": "177380b8-f015-4ab8-8ecf-2ab6141b1919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U spaCy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spaCy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spaCy)\n",
            "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spaCy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spaCy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spaCy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spaCy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spaCy\n",
            "  Attempting uninstall: spaCy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spaCy-3.7.2 weasel-0.3.4\n",
            "2023-11-21 08:47:16.627958: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-21 08:47:16.628017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-21 08:47:16.628041: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-21 08:47:16.633620: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-21 08:47:17.558018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eboUh4S-lXDL"
      },
      "source": [
        "# spaCy tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOOjE-sMlgKR"
      },
      "source": [
        "*Notice that the installation doesn’t automatically download the English model. We need to do that ourselves. (python -m spacy download en_core_web_lg)*\n",
        "\n",
        "Hello World in spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6qfXBODpGvF",
        "outputId": "31f256d9-303f-44f3-c0cc-0103a164c609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "doc = nlp('Hello World!')\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "World\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtf0Np7Ypntm"
      },
      "source": [
        "spaCy preserves this “link” between the word and its place in the raw text. Here’s how to get the exact index of a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfkVc7TKpoeu",
        "outputId": "9da4fbed-a2cd-44f6-8da1-80eb509122c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text + ' ', token.idx)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello  0\n",
            "World  6\n",
            "!  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qa9B12LuUnT"
      },
      "source": [
        "The **Token** class exposes a lot of word-level attributes. Here are a few examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxK2cH9ruV48",
        "outputId": "5e7fd2c9-d3a8-4f07-b425-d06cac114ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Next week I'll be in Rome.\")\n",
        "for token in doc:\n",
        "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
        "        token.text,\n",
        "        token.idx,\n",
        "        token.lemma_,\n",
        "        token.is_punct,\n",
        "        token.is_space,\n",
        "        token.shape_,\n",
        "        token.pos_,\n",
        "        token.tag_\n",
        "    ))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next\t0\tnext\tFalse\tFalse\tXxxx\tADJ\tJJ\n",
            "week\t5\tweek\tFalse\tFalse\txxxx\tNOUN\tNN\n",
            "I\t10\tI\tFalse\tFalse\tX\tPRON\tPRP\n",
            "'ll\t11\twill\tFalse\tFalse\t'xx\tAUX\tMD\n",
            "be\t15\tbe\tFalse\tFalse\txx\tAUX\tVB\n",
            "in\t18\tin\tFalse\tFalse\txx\tADP\tIN\n",
            "Rome\t21\tRome\tFalse\tFalse\tXxxx\tPROPN\tNNP\n",
            ".\t25\t.\tTrue\tFalse\t.\tPUNCT\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKw3AR3Iunjb"
      },
      "source": [
        "## Sentence detection\n",
        "Here’s how to achieve one of the most common NLP tasks with spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7AK_uofuobf",
        "outputId": "051377ee-a08b-402e-df9c-7ae357262b6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"These are apples. These are oranges.\")\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are apples.\n",
            "These are oranges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr5GaivKuxEt"
      },
      "source": [
        "## Part Of Speech Tagging\n",
        "PoS-tagging of a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SPCdMJhuxpI",
        "outputId": "d1d3b768-674c-4899-bd1c-e86b19d14a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Next week I'll be in Madrid.\")\n",
        "print([(token.text, token.pos_) for token in doc])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Next', 'ADJ'), ('week', 'NOUN'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('in', 'ADP'), ('Madrid', 'PROPN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIwj7h7gu0gs"
      },
      "source": [
        "## Named Entity Recognition\n",
        "Doing NER with spaCy is super easy and the pretrained model performs pretty well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkbmiqJLu2i8",
        "outputId": "0009a13a-9dcb-447d-8ff5-37e0528df781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Next week I'll be in Madrid.\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next week DATE\n",
            "Madrid GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn5sD_9FvEwo"
      },
      "source": [
        "You can also view the IOB style tagging of the sentence like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC4ytRWQvFDH",
        "outputId": "a2f5a119-7d73-405e-e8bb-7f52830817b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Next week I'll be in Madrid.\")\n",
        "iob_tagged = [\n",
        "    (\n",
        "        token.text,\n",
        "        token.tag_,\n",
        "        \"{0}-{1}\".format(token.ent_iob_, token.ent_type_) if token.ent_iob_ != 'O' else token.ent_iob_\n",
        "    ) for token in doc\n",
        "]\n",
        "print(iob_tagged)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Next', 'JJ', 'B-DATE'), ('week', 'NN', 'I-DATE'), ('I', 'PRP', 'O'), (\"'ll\", 'MD', 'O'), ('be', 'VB', 'O'), ('in', 'IN', 'O'), ('Madrid', 'NNP', 'B-GPE'), ('.', '.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14YgcbyvvYaG"
      },
      "source": [
        "The spaCy NER also has a healthy variety of entities. You can view the full list here: https://spacy.io/usage/linguistic-features#entity-types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZgmrVtAvXde",
        "outputId": "8bb02734-b885-494c-ee92-792a08a112eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 CARDINAL\n",
            "9 a.m. TIME\n",
            "30% PERCENT\n",
            "just 2 days DATE\n",
            "WSJ ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1O_1KWvkuN"
      },
      "source": [
        "Let’s use displaCy to view a beautiful visualization of the Named Entity annotated sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2s_Om6fvmmt",
        "outputId": "896d6a17-a834-4889-d1a2-f1ffd58beacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc = nlp('I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " shares at \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    9 a.m.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              " because the stock went up \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    30%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    just 2 days\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " according to the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    WSJ\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4gc6A62vvXJ"
      },
      "source": [
        "## Chunking\n",
        "spaCy automatically detects noun-phrases as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUDhlXVDvz1j",
        "outputId": "85a661b5-e666-4dbc-8b0c-1b6101a5eec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text, chunk.label_, chunk.root.text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall Street Journal NP Journal\n",
            "an interesting piece NP piece\n",
            "crypto currencies NP currencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvlq8h5WwKH4"
      },
      "source": [
        "Notice how the chunker also computes the root of the phrase, the main word of the phrase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O1Uqf3DwBNF"
      },
      "source": [
        "## Dependency Parsing\n",
        "\n",
        "Let’s see the dependency parser in action:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2OZOPInwLWF",
        "outputId": "5cfb4a21-4afd-4c82-fbb6-5e769dae455d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n",
        "\n",
        "for token in doc:\n",
        "    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n",
        "        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall/NNP <--compound-- Street/NNP\n",
            "Street/NNP <--compound-- Journal/NNP\n",
            "Journal/NNP <--nsubj-- published/VBD\n",
            "just/RB <--advmod-- published/VBD\n",
            "published/VBD <--ROOT-- published/VBD\n",
            "an/DT <--det-- piece/NN\n",
            "interesting/JJ <--amod-- piece/NN\n",
            "piece/NN <--dobj-- published/VBD\n",
            "on/IN <--prep-- piece/NN\n",
            "crypto/NNP <--compound-- currencies/NNS\n",
            "currencies/NNS <--pobj-- on/IN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4-eoMzRwac4"
      },
      "source": [
        "If this doesn’t help visualizing the dependency tree, displaCy comes in handy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZKy_d_Nwa3P",
        "outputId": "d4d35a70-ab32-45f5-e5ad-dfe986576d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "doc = nlp('Wall Street Journal just published an interesting piece on crypto currencies')\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"600394b41e4042d8bb5b23d161dd7d01-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Wall</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Street</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Journal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">just</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">published</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">an</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">interesting</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">piece</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">crypto</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">currencies</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 405.0,47.0 405.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M520,139.0 L512,127.0 528,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-6\" stroke-width=\"2px\" d=\"M430,137.0 C430,2.0 680.0,2.0 680.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M680.0,139.0 L688.0,127.0 672.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-600394b41e4042d8bb5b23d161dd7d01-0-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-600394b41e4042d8bb5b23d161dd7d01-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46M5S00nwmK9"
      },
      "source": [
        "Word Vectors\n",
        "------------------\n",
        "\n",
        "spaCy comes shipped with a Word Vector model as well. We’ll need to download a larger model for that: *(python -m spacy download en_core_web_lg)*\n",
        "\n",
        "The vectors are attached to spaCy objects: Token, Lexeme (a sort of unnatached token, part of the vocabulary), Span and Doc. The multi-token objects average its constituent vectors.\n",
        "\n",
        "Here are a few properties word vectors have:\n",
        "1. If two words are similar, they appear in similar contexts\n",
        "2. Word vectors are computed taking into account the context (surrounding words)\n",
        "3. Given the two previous observations, similar words should have similar word vectors\n",
        "4. Using vectors we can derive relationships (relatedness) between words\n",
        "\n",
        "Let’s see how we can access the embedding of a word in spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJDYKB84xV2C",
        "outputId": "84823174-6738-42c7-dadb-ecb342236898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(nlp.vocab['cat'].vector)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.7032e+00  4.1982e+00 -5.0002e+00 -1.1322e+01  3.1702e-02 -1.0255e+00\n",
            " -3.0870e+00 -3.7327e+00  5.3875e-01  3.5679e+00  6.9276e+00  1.5793e+00\n",
            "  5.1188e-01  3.1868e+00  6.1534e+00 -4.8941e+00 -2.9959e-01 -3.6276e+00\n",
            "  2.3825e+00 -1.4402e+00 -4.7577e+00  4.3607e+00 -4.9814e+00 -3.6672e+00\n",
            " -1.8052e+00 -2.1888e+00 -4.2875e+00  5.5712e+00 -5.2875e+00 -1.8346e+00\n",
            " -2.2015e+00 -7.7091e-01 -4.8260e+00  1.2464e+00 -1.7945e+00 -8.1280e+00\n",
            "  1.9994e+00  1.1413e+00  3.8032e+00 -2.8783e+00 -4.2136e-01 -4.4177e+00\n",
            "  7.7456e+00  4.9535e+00  1.7402e+00  1.8275e-01  2.4218e+00 -3.1496e+00\n",
            " -3.8057e-02 -2.9818e+00  8.3396e-01  1.1531e+01  3.5684e+00  2.5970e+00\n",
            " -2.8438e+00  3.2755e+00  4.5674e+00  3.2219e+00  3.4206e+00  1.1200e-01\n",
            "  1.0303e-01 -5.8396e+00  4.6370e-01  2.7750e+00 -5.3713e+00 -5.0247e+00\n",
            " -2.0212e+00  5.8772e-01  1.1569e+00  1.3224e+00  4.3994e+00  2.0444e+00\n",
            "  2.1343e+00 -1.9023e+00  2.1469e+00 -2.9085e+00  4.8429e-01 -3.3544e-01\n",
            "  1.4484e+00 -1.5770e+00 -1.1307e+00  2.8320e+00  6.2041e-01  3.7994e+00\n",
            " -3.1162e-01 -6.9221e+00  7.1342e+00  7.2441e+00 -8.9326e+00 -2.7927e+00\n",
            "  2.6613e-01  6.7547e-01  6.7293e+00 -5.8127e+00  3.1567e+00 -1.0634e+00\n",
            " -1.5733e+00  1.3534e+00  3.9218e-01 -8.7077e+00  3.4229e-02  3.3251e+00\n",
            "  4.6713e+00  1.1865e-02  9.8345e-01 -5.3206e-02 -9.1613e+00  6.0161e+00\n",
            " -2.2223e+00  2.5015e+00 -6.0702e-01 -3.6344e-02  7.1884e+00 -1.4431e+00\n",
            "  2.6156e+00 -1.0148e+00  4.1225e+00 -1.8472e+00  4.6292e+00 -2.6506e+00\n",
            " -1.8937e+00  4.1749e+00 -9.6644e+00 -2.4813e+00 -2.7637e+00 -1.0624e+00\n",
            "  3.5988e+00  4.9833e+00  6.4499e-01  2.5784e-01  9.8727e-01 -4.2485e+00\n",
            "  3.4272e-01 -2.2270e+00 -1.8957e+00  8.0796e-01 -2.0265e+00 -6.1828e+00\n",
            " -2.2378e+00  2.8216e+00 -2.0050e+00 -3.8924e+00 -2.9364e-01 -1.6128e+00\n",
            " -6.7874e-01 -1.9855e+00  1.8221e-01  2.1575e+00  4.9825e-01 -1.7326e+00\n",
            "  4.7886e+00  2.9904e+00  8.3447e-01 -4.7417e+00  2.4697e+00  1.3751e+00\n",
            "  4.5358e+00  6.5386e-01  5.5413e+00  2.3963e+00  1.0031e+00 -8.0664e-01\n",
            " -1.4126e+00  2.8689e+00 -8.7339e+00 -2.7457e+00 -3.1805e-01 -2.4484e-01\n",
            "  3.7117e+00 -1.8636e+00  2.9959e-01  6.5062e-02 -1.5682e+00  1.5876e+00\n",
            "  6.9224e-01 -6.7734e+00  3.1065e+00  2.3973e+00 -3.5138e+00  3.4460e+00\n",
            "  3.4252e+00 -5.1906e+00 -6.9372e-01  1.9435e+00 -1.5669e-01  1.9710e+00\n",
            "  8.7743e-01 -8.3110e+00 -4.0306e-01 -5.0165e+00 -5.6309e-02  4.9249e+00\n",
            " -7.1053e+00 -5.2338e+00  2.3535e+00 -2.5255e+00 -2.7785e+00  5.0149e+00\n",
            " -2.8405e+00 -1.8614e+00  2.8818e-03  1.3281e+00  1.0194e+00  3.5155e+00\n",
            "  2.7971e-01  1.3251e+00  1.4386e+00 -6.1719e-01 -2.6864e+00 -3.9613e+00\n",
            "  4.5749e+00 -1.0939e+00  1.3289e+00 -9.5484e-01 -5.4675e+00  2.1607e+00\n",
            "  5.0715e-01  1.4860e-01 -4.8571e+00 -2.2213e+00 -2.3498e-01 -4.2629e+00\n",
            " -8.7002e-01  3.3796e+00 -4.3989e+00  6.1047e+00  3.7927e+00 -6.0760e+00\n",
            "  3.1840e+00 -8.3104e-01 -5.4015e+00 -6.2916e+00  1.2497e+00  1.8026e+00\n",
            " -3.4535e+00 -2.1652e-01 -1.4958e+00  5.7946e-01  2.2505e+00  2.0868e+00\n",
            "  3.9621e-01  1.6076e+00  4.0635e+00 -3.4088e+00 -1.0590e+00 -3.6376e+00\n",
            "  2.0501e+00  1.4785e+00 -1.8906e+00 -2.6215e-01 -5.1386e+00  3.7029e+00\n",
            " -1.8151e+00 -3.2759e+00 -5.1866e+00  2.5485e-01 -4.5696e+00  1.0147e+01\n",
            " -3.0195e+00 -2.4640e+00  7.5459e-01 -5.6395e+00 -5.4095e+00 -2.4363e+00\n",
            " -4.3922e-01 -4.0911e+00 -3.5194e+00  1.8031e+00 -1.3644e-01  6.7990e+00\n",
            "  5.8461e+00  5.3452e-01  1.1042e+00  3.5698e+00  4.4668e+00 -2.4537e+00\n",
            " -2.1832e+00  1.5293e+00 -1.9414e+00 -8.8675e-02 -1.1825e+00 -3.9996e+00\n",
            "  2.8077e+00 -1.8000e+00  4.2545e+00 -1.3813e+00 -2.2921e+00  3.7889e+00\n",
            " -1.5837e+00 -7.2078e-01  4.7743e+00 -3.0923e+00  8.4709e+00  3.0132e-01\n",
            " -5.6173e+00 -5.4610e-01 -4.8459e+00  6.0303e+00 -6.9664e+00  3.1445e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QlrERavxhhJ"
      },
      "source": [
        "There’s a really famous example of word embedding math: \"man\" - \"woman\" + \"queen\" = \"king\". It sounds pretty crazy to be true, so let’s test that out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQNit67xiER",
        "outputId": "de4cc605-33e9-48c6-9dd7-cc60573a54a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
        "\n",
        "man = nlp.vocab['man'].vector\n",
        "woman = nlp.vocab['woman'].vector\n",
        "queen = nlp.vocab['queen'].vector\n",
        "king = nlp.vocab['king'].vector\n",
        "\n",
        "# We now need to find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
        "maybe_king = man - woman + queen\n",
        "computed_similarities = []\n",
        "\n",
        "for word in nlp.vocab:\n",
        "    # Ignore words without vectors\n",
        "    if not word.has_vector:\n",
        "        continue\n",
        "\n",
        "    similarity = cosine_similarity(maybe_king, word.vector)\n",
        "    computed_similarities.append((word, similarity))\n",
        "\n",
        "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
        "print([w[0].text for w in computed_similarities[:10]])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['queen', 'man', 'king', 'woman', 'he', 'nothin’', \"'cause\", \"'Cause\", 'He', 'That']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XFNQ-FjxuQN"
      },
      "source": [
        "Computing Similarity\n",
        "---------------------------\n",
        "\n",
        "Based on the word embeddings, spaCy offers a similarity interface for all of it’s building blocks: Token, Span, Doc and Lexeme. Here’s how to use that similarity interface:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BYg824RxyBF",
        "outputId": "be5fef5f-d310-4aa9-c4b5-568f59c6f046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "banana = nlp.vocab['banana']\n",
        "dog = nlp.vocab['dog']\n",
        "fruit = nlp.vocab['fruit']\n",
        "animal = nlp.vocab['animal']\n",
        "\n",
        "print(\"sim(dog, animal) =\",dog.similarity(animal))\n",
        "print(\"sim(dog,fruit) =\", dog.similarity(fruit))\n",
        "print(\"sim(banana,fruit) = \", banana.similarity(fruit))\n",
        "print(\"sim(banana,animal) = \", banana.similarity(animal))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim(dog, animal) = 0.5192115902900696\n",
            "sim(dog,fruit) = 0.13643456995487213\n",
            "sim(banana,fruit) =  0.6650428175926208\n",
            "sim(banana,animal) =  0.18752224743366241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUj3bn3nx2Cv"
      },
      "source": [
        "Let’s now use this technique on entire texts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGHGZ92Ax0X8",
        "outputId": "6f1353ab-ba36-456f-e20b-430981d02b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "target = nlp(\"Cats are beautiful animals.\")\n",
        "\n",
        "doc1 = nlp(\"Dogs are awesome.\")\n",
        "doc2 = nlp(\"Some gorgeous creatures are felines.\")\n",
        "doc3 = nlp(\"Dolphins are swimming mammals.\")\n",
        "\n",
        "print(target.similarity(doc1))\n",
        "print(target.similarity(doc2))\n",
        "print(target.similarity(doc3))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.925293344292394\n",
            "0.9067517259890845\n",
            "0.9037427153904276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7stnhdEG1otz"
      },
      "source": [
        "Extending spaCy\n",
        "----------------------\n",
        "\n",
        "The entire spaCy architecture is built upon three building blocks: Document (the big encompassing container), Token (most of the time, a word) and Span (set of consecutive Tokens). The extensions you create can add extra functionality to anyone of the these components. There are some examples out there for what you can do. Let’s create an extension ourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv0DySlx1y81"
      },
      "source": [
        "### Creating Document level Extension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMQObGdN1uSV",
        "outputId": "619df90f-e00b-49ed-bffa-ff0d1efe63e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "import nltk\n",
        "\n",
        "from spacy.tokens import Doc\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "def polarity_scores(doc):\n",
        "    return sentiment_analyzer.polarity_scores(doc.text)\n",
        "\n",
        "Doc.set_extension('polarity_scores', getter=polarity_scores, force=True)\n",
        "\n",
        "doc = nlp(\"I love dogs and cats.\")\n",
        "print(doc._.polarity_scores)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.6369}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "183lR9H945sx",
        "outputId": "3b302231-9284-410a-b845-b90d961c2298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(\"Today is a nice day!!!\")\n",
        "print(doc._.polarity_scores)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.449, 'pos': 0.551, 'compound': 0.5684}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I love my dog, but I hate cats.\")\n",
        "print(doc._.polarity_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0YIxQZWmuZv",
        "outputId": "2f0675ef-19f9-4c25-e0c1-5bfe19474e76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.433, 'neu': 0.343, 'pos': 0.223, 'compound': -0.5346}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBidAVbO13iP"
      },
      "source": [
        "One can easily create extensions for every component type. Such extensions only have access to the context of that component. What happens if you need the tokenized text along with the Part-Of-Speech tags. Let’s now build a custom pipeline. Pipelines are another important abstraction of spaCy. The nlp object goes through a list of pipelines and runs them on the document. For example the tagger is ran first, then the parser and ner pipelines are applied on the already POS annotated document. Here’s how the nlp default pipeline structure looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOTb6yq16PB",
        "outputId": "67d305d8-806a-47b8-b9b0-657437ac6daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(nlp.pipeline)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7dadb33c5600>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7dadb33c4c40>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7dadb34bd850>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7dadb31cd080>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7dadb31c26c0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7dadb34bd8c0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swF1evPI3WQd"
      },
      "source": [
        "### Creating a custom pipeline\n",
        "\n",
        "Let’s build a custom pipeline that needs to be applied after the tagger pipeline is ran. We need the POS tags to get the Synset from Wordnet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP2BLM9O3YlX",
        "outputId": "2d4f8b12-b41e-4cd5-df96-0660291d01ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from spacy.tokens import Token\n",
        "from spacy.language import Language\n",
        "\n",
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('N'):\n",
        "        return 'n'\n",
        "\n",
        "    if tag.startswith('V'):\n",
        "        return 'v'\n",
        "\n",
        "    if tag.startswith('J'):\n",
        "        return 'a'\n",
        "\n",
        "    if tag.startswith('R'):\n",
        "        return 'r'\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "class WordnetPipeline(object):\n",
        "    def __init__(self, nlp):\n",
        "        Token.set_extension('synset', default=None, force=True)\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        for token in doc:\n",
        "            wn_tag = penn_to_wn(token.tag_)\n",
        "            if wn_tag is None:\n",
        "                continue\n",
        "\n",
        "            ss = wn.synsets(token.text, wn_tag)[0]\n",
        "            token._.set('synset', ss)\n",
        "\n",
        "        return doc\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "@Language.factory(\"wordnet_pipe\")\n",
        "def wordnet_pipe(nlp, name):\n",
        "    return WordnetPipeline(nlp)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the new pipeline."
      ],
      "metadata": {
        "id": "uLLELR7eq3oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe(\"wordnet_pipe\")\n",
        "doc = nlp(\"Paris is the awesome capital of France.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, \"-\", token._.synset)\n",
        "\n",
        "# Let’s see how the pipeline structure looks like\n",
        "print(nlp.pipeline)\n",
        "\n",
        "nlp.remove_pipe(\"wordnet_pipe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PMTLTuQq5s7",
        "outputId": "1f1a41a9-fc5d-410d-f5f5-bd920afa0062"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris - Synset('paris.n.01')\n",
            "is - Synset('be.v.01')\n",
            "the - None\n",
            "awesome - Synset('amazing.s.02')\n",
            "capital - Synset('capital.n.01')\n",
            "of - None\n",
            "France - Synset('france.n.01')\n",
            ". - None\n",
            "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7dadb33c5600>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7dadb33c4c40>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7dadb34bd850>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7dadb31cd080>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7dadb31c26c0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7dadb34bd8c0>), ('wordnet_pipe', <__main__.WordnetPipeline object at 0x7dadb31752a0>)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('wordnet_pipe', <__main__.WordnetPipeline at 0x7dadb31752a0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}